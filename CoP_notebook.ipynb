{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0388019d",
   "metadata": {},
   "source": [
    "# **Data and Evidence CoP**\n",
    "## Introduction to APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff63f2",
   "metadata": {},
   "source": [
    "We will start by bringing in packages to our coding environment. These packages contain functions that allow us to do different things within our code.\n",
    "\n",
    "We will be using:\n",
    "- `requests`: a package for interacting with APIs\n",
    "- `pandas`: given the short-form `pd`, is a package for working with dataframes, a type of data structure in Python that resembles a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ca75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14acfe33",
   "metadata": {},
   "source": [
    "Now that we have installed all the functions that we need, we can start to define some variables that we need to access our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://environment.data.gov.uk/hydrology/id/stations\"\n",
    "print(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34623f",
   "metadata": {},
   "source": [
    "If we visit that link, we can see it returns a lot of stations, 100 in fact. This is because that is the soft limit of the API, meaning that unless we specify a limit, or there are fewer than 1,000 items in the request, it will display the first 100 entries.\n",
    "Let's set a limit so we only get the first ten entries.\n",
    "\n",
    "Note that we have already defined the base url and the stations url, so we don't need to do this again.\n",
    "To add a query to our URL, we first need to add a `?` and then we define our query. We put an `&` between each query if we have more than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_query = \"?_limit=10\"\n",
    "stations_10_url = base_url + limit_query\n",
    "print(stations_10_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425b9d2",
   "metadata": {},
   "source": [
    "Now that we're familiar with constructing a URL for accessing data, let's expand on this work by using the `requests` library to bring this data into our environment.\n",
    "\n",
    "We use the `requests.get()` function to do this. \n",
    "\n",
    "This link provides more information on this method: \n",
    "https://www.w3schools.com/PYTHON/ref_requests_get.asp#:~:text=The%20get%28%29%20method%20sends%20a%20GET%20request%20to,timeout%3D2.50%29%20Required.%20The%20url%20of%20the%20request%20Optional\n",
    "\n",
    "In summary, the get() method sends a GET request. We provide it with a URL, and it accesses this URL, and simply \"gets\" some information from it.\n",
    "\n",
    "Let's put our stations_10_url into the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b50a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_10_response = requests.get(stations_10_url)\n",
    "print(stations_10_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03fc70",
   "metadata": {},
   "source": [
    "If we print our return from this function, it tells us that the status code of the response was 200. This means the request was successful. You don't need to understand status codes in much detail, but a status code of 200 will mean the response was received successfully.\n",
    "\n",
    "Let's view the response.\n",
    "\n",
    "We use an if statement in the code block. This just says: if the status code was 200, do this, and if the status code was anything else, do that.\n",
    "\n",
    "First, we are going to take the response, and put it into a JSON format. We are going to print the keys to the JSON response so we can see what content was included in the JSON we recieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if stations_10_response.status_code == 200:\n",
    "    stations_10_json = stations_10_response.json()\n",
    "    print(stations_10_json.keys())\n",
    "else:\n",
    "    print(f\"Error: {stations_10_response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40680706",
   "metadata": {},
   "source": [
    "We can see that the JSON is made of two main elements, the `meta` and the `items`.\n",
    "\n",
    "Meta contains metadata on things such as publisher and licenses.\n",
    "\n",
    "In our case, we are interested in the items section, as this contains information on each station.\n",
    "\n",
    "Let's look into the items in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = stations_10_json['items']\n",
    "stations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bf6f1",
   "metadata": {},
   "source": [
    "We have successfully pulled in data from an API into our environment in JSON format.\n",
    "\n",
    "After a while you get used to reading data in JSON format, but it isn't the nicest thing to view. Let's convert it to a DataFrame.\n",
    "\n",
    "A DataFrame is a way of displaying data in a table format. It is much easier to look at and work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.DataFrame(stations)\n",
    "stations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841371e",
   "metadata": {},
   "source": [
    "We have successfully pulled in data using an API.\n",
    "\n",
    "This isn't the most interesting dataset though. Let's access some slightly more interesting data and use a more complex query than just a limit.\n",
    "\n",
    "We are going to make use of API documentation to do this. A good API should have documentation that goes alongside it. This documentation will tell you how you can access different parts of the data, and how you can query the data. Let's look at the API documentation for this data:\n",
    "\n",
    "**INSERT LINK HERE**\n",
    "\n",
    "We can define the `parameters` of our query and use them in our request. This is a nicer way of writing a request than making a longer and longer URL.\n",
    "\n",
    "The block of code below puts everything together that we have covered, and also introduces the `params` query method. While using Python to access data via an API might seem complicated right now, you can start to see that there really isn't too many steps to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "readings_url = \"https://environment.data.gov.uk/hydrology/data/readings.json\"\n",
    "\n",
    "params = {\n",
    "    \"station\": \"052d0819-2a32-47df-9b99-c243c9c8235b\",\n",
    "    \"observedProperty\": \"waterFlow\",\n",
    "    \"mineq-date\": \"2025-01-01\",\n",
    "    \"maxeq-date\": \"2025-01-07\"\n",
    "}\n",
    "\n",
    "reading_response = requests.get(readings_url, params=params)\n",
    "print(reading_response.url)\n",
    "\n",
    "if reading_response.status_code == 200:\n",
    "    flow_json = reading_response.json()\n",
    "    flow_df = pd.DataFrame(flow_json['items'])\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Error\")\n",
    "\n",
    "flow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9ed96",
   "metadata": {},
   "source": [
    "To demonstrate what is possible, here is a few lines of code to visualise this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f68b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.lineplot(y=\"value\", x=\"dateTime\", data=flow_df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a856ad",
   "metadata": {},
   "source": [
    "Not a great looking plot. Let's neaten up the axes by adding some appropriate ticks and labels, as well as a title for the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "g = sns.lineplot(y=\"value\", x=\"dateTime\", data=flow_df)\n",
    "\n",
    "g.set_xticks([\n",
    "    \"2025-01-01T00:00:00\",\n",
    "    \"2025-01-02T00:00:00\",\n",
    "    \"2025-01-03T00:00:00\",\n",
    "    \"2025-01-04T00:00:00\",\n",
    "    \"2025-01-05T00:00:00\",\n",
    "    \"2025-01-06T00:00:00\",\n",
    "    \"2025-01-07T00:00:00\",\n",
    "    \"2025-01-08T00:00:00\"\n",
    "],\n",
    "[\n",
    "    \"1 Jan\",\n",
    "    \"2 Jan\",\n",
    "    \"3 Jan\",\n",
    "    \"4 Jan\",\n",
    "    \"5 Jan\",\n",
    "    \"6 Jan\",\n",
    "    \"7 Jan\",\n",
    "    \"8 Jan\"\n",
    "])\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Flow (mÂ³/s)\")\n",
    "plt.title(\"Flow Time Series at Ulting Sarasota\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1cc5f0",
   "metadata": {},
   "source": [
    "This has been a very quick introduction to this topic. If you want to learn more about this work, I recommend making use of our partnership with DataCamp. They offer interactive courses on a variety of topics relating to working with data.\n",
    "\n",
    "If you are new to Python, I recommend starting with the Introduction to Python course, which teaches you the basics of Python in just a few hours.\n",
    "\n",
    "https://app.datacamp.com/learn/courses/intro-to-python-for-data-science\n",
    "\n",
    "After completing this, it is worth making use of the Python Fundamentals skill track, which is a collection of courses that build on from each other. By the end you should have a good idea of the basics of Python and are ready to start looking into more specific uses.\n",
    "\n",
    "https://app.datacamp.com/learn/skill-tracks/python-data-fundamentals\n",
    "\n",
    "After completing this, or if you already have a bit of experience working with Python and want to learn more on working with APIs, then I recommend the Importing and CLeaning Data in Python skill track. This collection of courses looks at lots of the content we have explored today, but gives you much more content and will teach you how to import data from files and the internet, and then how to clean the data so it is easier to work with. By the end of this skill track, you should have a good level of skills for working with APIs and will be more than ready to start work on your own projects.\n",
    "\n",
    "https://app.datacamp.com/learn/skill-tracks/importing-cleaning-data-with-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
